{"cells":[{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"import json\nimport pandas as pd\ntrain = pd.read_json('../input/whats-cooking-kernels-only/train.json')\ntest = pd.read_json('../input/whats-cooking-kernels-only/test.json')\n\nfrom sklearn.model_selection import train_test_split\nX_train = list(train['ingredients'])\ny_train = list(train['cuisine'])\nX_test = list(test['ingredients'])\n\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize\n\nstop_words = set(stopwords.words('english'))\n\nfrom nltk.stem.porter import *\nstemmer = PorterStemmer()\n\nfrom nltk.corpus import stopwords\ndef preprocess_ingredient(ingredients):\n    for ingredient in ingredients:\n        for i in range(len(ingredient)):\n            x = ingredient[i] #'Bertolli® Classico Olive Oil', '(10 oz.) frozen chopped spinach, thawed and squeezed dry' ,'leg of lamb', 'lamb leg'\n            x = x.lower() #'bertolli® classico olive oil', '(10 oz.) frozen chopped spinach, thawed and squeezed dry' ,'leg of lamb', 'lamb leg'\n            x = re.sub(\"[^a-z ]\", \"\", x) #'bertolli classico olive oil', ' oz frozen chopped spinach thawed and squeezed dry' ,'leg of lamb', 'lamb leg'\n            word_tokens = word_tokenize(x)\n            if 'oz' in word_tokens:\n                word_tokens.remove('oz')\n            filtered_words = [w for w in word_tokens if not w in stop_words] \n            filtered_words.sort() #['bertolli', 'classico', 'oil', 'olive'], ['chopped', 'dry', 'frozen', 'spinach', 'squeezed', 'thawed'], ['lamb', 'leg'], ['lamb', 'leg']\n            stemmed_word = [stemmer.stem(word) for word in filtered_words]\n            x = ' '.join(stemmed_word) #'bertolli classico oil oliv', 'chop dri frozen spinach squeez thaw' ,'lamb leg', 'lamb leg'\n            ingredient[i] = x\n            \npreprocess_ingredient(X_train)\npreprocess_ingredient(X_test)\n\nvocabs = set()\nfor ingredient in X_train:\n    vocabs.update(ingredient)\n\ndef create_bag_of_words(ingredients):\n    data_features = list()\n    for ingredient in ingredients:\n        features = list()\n        for item in vocabs:\n            features.append(item in ingredient)\n        data_features.append(features)\n    return data_features\n\ntrain_data_features = create_bag_of_words(X_train)\n\ndef train_logistic_regression(features, label):\n    from sklearn.linear_model import LogisticRegression\n    ml_model = LogisticRegression(C = 2,random_state = 0)\n    ml_model.fit(features, label)\n    return ml_model\n\nml_model = train_logistic_regression(train_data_features, y_train)\n\ntest_data_features = create_bag_of_words(X_test)\npredicted_y = ml_model.predict(test_data_features)\n\ntest['cuisine'] = predicted_y\ntest[['id', 'cuisine']].to_csv('submission.csv', index=False)\ntest[['id', 'cuisine']].head()","execution_count":1,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","name":"stderr"},{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"      id       cuisine\n0  18009       british\n1  28583   southern_us\n2  41580       italian\n3  29752  cajun_creole\n4  35687       italian","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>cuisine</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18009</td>\n      <td>british</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28583</td>\n      <td>southern_us</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41580</td>\n      <td>italian</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>29752</td>\n      <td>cajun_creole</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35687</td>\n      <td>italian</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}],"metadata":{"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}